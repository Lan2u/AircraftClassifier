{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os.path\n",
    "import psycopg2\n",
    "\n",
    "import configparser\n",
    "\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the sql script used for getting images and details from database.\n",
    "SELECT_IMAGE_SCRIPT_PATH = \"database/select_aircraft_images.sql\"\n",
    "\n",
    "# Used as a performance argument.\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Batch size for data set to process.\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# The file used for caching the dataset.\n",
    "DATASET_CACHE_FILE = \"dataset_cache\"\n",
    "\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBConfig:\n",
    "    def __init__(self, filename, host, port, db_name, user, pwd):\n",
    "        self.filename = filename\n",
    "        self.host = host\n",
    "        self.port = port\n",
    "        self.db_name = db_name\n",
    "        self.user = user\n",
    "        self.pwd = pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(filename = 'database.ini', section = 'aircraft_postgres_db'):\n",
    "    parser = configparser.ConfigParser()\n",
    "    parser.read(filename)\n",
    "    cfg = parser[section]\n",
    "    return DBConfig(filename, cfg['Host'], int(cfg['Port']), cfg['Db_name'], cfg['User'], cfg['Pass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sql(filename):\n",
    "    with open(filename, \"r\") as sql_script_file:\n",
    "        return sql_script_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ready_image(path):\n",
    "    # Path must be transformed into the actual image.\n",
    "    \n",
    "#     # Variant name is the variantid of the image.\n",
    "#     variant_id = image_details[1]\n",
    "\n",
    "#     path = image_details[0]\n",
    "#     label = image_details[1]\n",
    "    \n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    \n",
    "    print(img)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prepare_image_dataset(image_paths, labels):\n",
    "    image_paths_dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    \n",
    "    print(image_paths_dataset)\n",
    "    \n",
    "    ds = image_paths_dataset.map(ready_image)\n",
    "    \n",
    "    print(ds)\n",
    "    \n",
    "#     ds = ds.cache(DATASET_CACHE_FILE)\n",
    "    \n",
    "    \n",
    "    # ds = ds.repeat()\n",
    "    \n",
    "    \n",
    "#     ds = ds.batch(BATCH_SIZE)\n",
    "#     ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_images(image_paths):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(image_paths);\n",
    "    for (path, variant_name) in image_paths:\n",
    "        img = read_parse_image(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://www.tensorflow.org/tutorials/load_data/images (09/06/2020)\n",
    "def show_batch(image_batch, label_batch):\n",
    "  plt.figure(figsize=(10,10))\n",
    "  for n in range(25):\n",
    "      ax = plt.subplot(5,5,n+1)\n",
    "      plt.imshow(image_batch[n])\n",
    "      plt.title(label_batch[n].title())\n",
    "      plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_cfg = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname=db_cfg.db_name, user=db_cfg.user, password=db_cfg.pwd, host=db_cfg.host, port=db_cfg.port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to database, version: ('PostgreSQL 12.3, compiled by Visual C++ build 1914, 64-bit',)\n"
     ]
    }
   ],
   "source": [
    "cur = conn.cursor()\n",
    "cur.execute('SELECT version()')\n",
    "print(\"Connected to database, version: \" + str(cur.fetchone()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_image_sql = load_sql(SELECT_IMAGE_SCRIPT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(select_image_sql)\n",
    "training_data = cur.fetchmany(size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "    img = tf.image.decode_jpeg(img, channels=3) #color images\n",
    "\n",
    "    #convert unit8 tensor to floats in the [0,1]range\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    \n",
    "    #resize the image into 224*224\n",
    "    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img_path(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = decode_img(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img_data(img_data):\n",
    "    path = img_data[0]\n",
    "    label = img_data[1]\n",
    "    img = process_img_path(path)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 training images\n",
      "Image shape:  (128, 128, 3)\n",
      "Label:  408\n"
     ]
    }
   ],
   "source": [
    "# Split the training image paths from the labels.\n",
    "image_paths, labels = zip(*training_data)\n",
    "\n",
    "image_paths = list(image_paths)\n",
    "labels = list(labels)\n",
    "\n",
    "image_data = list(map(process_img_path, image_paths))\n",
    "\n",
    "# ds = tf.data.Dataset.from_tensor_slices(training_data)\n",
    "\n",
    "# labeled_ds = ds.map(process_img_data, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# print(image_paths)\n",
    "\n",
    "# image_paths = list(map(lambda x : (x[0], str(x[1])), image_paths))\n",
    "\n",
    "image_count = len(labels)\n",
    "\n",
    "print(\"Loaded {} training images\".format(image_count))\n",
    "\n",
    "# print(image_data)\n",
    "\n",
    "labeled_ds = tf.data.Dataset.from_tensor_slices((image_data, labels))\n",
    "\n",
    "for image, label in labeled_ds.take(1):\n",
    "    print(\"Image shape: \", image.numpy().shape)\n",
    "    print(\"Label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "\n",
    "# images = prepare_image_dataset(image_paths, labels)\n",
    "\n",
    "\n",
    "# for x in image_paths:\n",
    "#     image_data.append(ready_image(x))\n",
    "\n",
    "# print(image_data)\n",
    "    \n",
    "# img_batch, label_batch = next(iter(image_dataset))\n",
    "\n",
    "# show_batch(img_batch.numpy(), label_batch.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data is now loaded and ready, time to actually handle the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam',\n",
    "#               loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 128, 128, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               8389120   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 8,413,217\n",
      "Trainable params: 8,413,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_data = image_data.batch(10)\n",
    "\n",
    "batch_labeled_ds = labeled_ds.batch(10)\n",
    "batch_labeled_ds = batch_labeled_ds.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10/10 [==============================] - 1s 60ms/step - loss: 5.1910e-05 - accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 1s 61ms/step - loss: 5.1910e-05 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "epochs = 3\n",
    "\n",
    "history = model.fit(batch_labeled_ds, epochs=2, steps_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_air",
   "language": "python",
   "name": "venv_air"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
